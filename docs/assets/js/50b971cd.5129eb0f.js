"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[7966],{4128(e,i,n){n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"ch6-ml-robotics","title":"Chapter 6: Machine Learning for Robotics","description":"ML for Robotics","source":"@site/docs/ch6-ml-robotics.md","sourceDirName":".","slug":"/ch6-ml-robotics","permalink":"/Physical-AI-Humanoid-Robotics/docs/ch6-ml-robotics","draft":false,"unlisted":false,"editUrl":"https://github.com/vandanachohan/Physical-AI-Humanoid-Robotics/edit/main/docs/ch6-ml-robotics.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_label":"Chapter 6: Machine Learning for Robotics","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Control Systems for Robotics","permalink":"/Physical-AI-Humanoid-Robotics/docs/ch5-control-systems"},"next":{"title":"Chapter 7: Computer Vision in Robotics","permalink":"/Physical-AI-Humanoid-Robotics/docs/ch7-computer-vision"}}');var t=n(4848),r=n(8453);const s={sidebar_label:"Chapter 6: Machine Learning for Robotics",sidebar_position:6},a="Chapter 6: Machine Learning for Robotics",c={},l=[{value:"ML for Robotics",id:"ml-for-robotics",level:2}];function h(e){const i={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"chapter-6-machine-learning-for-robotics",children:"Chapter 6: Machine Learning for Robotics"})}),"\n",(0,t.jsx)(i.h2,{id:"ml-for-robotics",children:"ML for Robotics"}),"\n",(0,t.jsx)(i.p,{children:"Machine learning in robotics enables systems to improve performance through experience. Key applications include:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Learning from demonstration: Teaching robots tasks through human examples"}),"\n",(0,t.jsx)(i.li,{children:"Reinforcement learning: Learning optimal behaviors through reward signals"}),"\n",(0,t.jsx)(i.li,{children:"Imitation learning: Replicating expert behaviors"}),"\n",(0,t.jsx)(i.li,{children:"Deep learning: Processing complex sensor data like images and point clouds"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Challenges include sample efficiency, safety during learning, and real-time inference requirements."})]})}function d(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453(e,i,n){n.d(i,{R:()=>s,x:()=>a});var o=n(6540);const t={},r=o.createContext(t);function s(e){const i=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(r.Provider,{value:i},e.children)}}}]);